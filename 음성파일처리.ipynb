{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30418,
     "status": "ok",
     "timestamp": 1742952190617,
     "user": {
      "displayName": "기모띠",
      "userId": "12217281576736575114"
     },
     "user_tz": -540
    },
    "id": "ly5V36KDs-gi",
    "outputId": "156a81bb-8188-4ef8-9497-1db06750f98f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.7/34.7 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m898.7/898.7 kB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m818.9/818.9 kB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.9/125.9 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m824.8/824.8 kB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m960.9/960.9 kB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.0/823.0 kB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.8/231.8 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for kiwipiepy_model (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install -q \\\n",
    "    pyannote.audio \\\n",
    "    faiss-cpu \\\n",
    "    sentence-transformers \\\n",
    "    openai \\\n",
    "    langchain_experimental \\\n",
    "    kiwipiepy \\\n",
    "    torchaudio \\\n",
    "    torch \\\n",
    "    numpy \\\n",
    "    pandas \\\n",
    "    tqdm \\\n",
    "    huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25885,
     "status": "ok",
     "timestamp": 1742951660486,
     "user": {
      "displayName": "기모띠",
      "userId": "12217281576736575114"
     },
     "user_tz": -540
    },
    "id": "Qgh6VSLQAif8",
    "outputId": "142622b8-4087-4c28-88a0-a4603b0a088e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2314,
     "status": "ok",
     "timestamp": 1742952199831,
     "user": {
      "displayName": "기모띠",
      "userId": "12217281576736575114"
     },
     "user_tz": -540
    },
    "id": "FDnItIdatSzs",
    "outputId": "ae2dd6b9-9975-45a6-92ca-ad2d96162bd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (0.25.1)\n"
     ]
    }
   ],
   "source": [
    "pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2309,
     "status": "ok",
     "timestamp": 1742952202141,
     "user": {
      "displayName": "기모띠",
      "userId": "12217281576736575114"
     },
     "user_tz": -540
    },
    "id": "yfuIaotytXsl",
    "outputId": "ec3bf3b8-35cb-4f26-8ade-d6f5f59e2c56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymysql in /usr/local/lib/python3.11/dist-packages (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2812,
     "status": "ok",
     "timestamp": 1742952204955,
     "user": {
      "displayName": "기모띠",
      "userId": "12217281576736575114"
     },
     "user_tz": -540
    },
    "id": "yAAdrFbotZE7",
    "outputId": "6dbe52eb-d390-4163-ed44-ebbeaa46e112"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.21)\n",
      "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.11/dist-packages (0.3.10)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.48)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.7)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.18)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.39)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.68.2)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.9.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.9.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain) (3.0.0)\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2413,
     "status": "ok",
     "timestamp": 1742952207369,
     "user": {
      "displayName": "기모띠",
      "userId": "12217281576736575114"
     },
     "user_tz": -540
    },
    "id": "r_WZOMnEtagb",
    "outputId": "b037a65d-04e9-4796-855a-2475da6f76d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (0.115.12)\n",
      "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (0.34.0)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (0.46.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi) (2.10.6)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.12.2)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.1.8)\n",
      "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.27.2)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install fastapi uvicorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8723,
     "status": "ok",
     "timestamp": 1742952216093,
     "user": {
      "displayName": "기모띠",
      "userId": "12217281576736575114"
     },
     "user_tz": -540
    },
    "id": "-O_9mPMAt3pT",
    "outputId": "7169b83b-97e0-4deb-effc-771f834cfee9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-oyy9tz3l\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-oyy9tz3l\n",
      "  Resolved https://github.com/openai/whisper.git to commit 517a43ecd132a2089d85f4ebc044728a71d49f6e\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (10.6.0)\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (0.60.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (2.0.2)\n",
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (0.9.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (2.6.0+cu124)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (4.67.1)\n",
      "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (3.2.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper==20240930) (0.43.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20240930) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper==20240930) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper==20240930) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/openai/whisper.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12928,
     "status": "ok",
     "timestamp": 1742963672304,
     "user": {
      "displayName": "기모띠",
      "userId": "12217281576736575114"
     },
     "user_tz": -540
    },
    "id": "J5vxTAVXs_Zb",
    "outputId": "246b72e3-9df4-4630-a55b-f31beacb71d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 실행 기기: cuda\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import torch\n",
    "import faiss\n",
    "import numpy as np\n",
    "import openai\n",
    "from pyannote.audio import Pipeline\n",
    "import whisper\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from collections import Counter\n",
    "from kiwipiepy import Kiwi\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "from pydub import AudioSegment\n",
    "# send pipeline to GPU (when available)\n",
    "import torch\n",
    "import pymysql\n",
    "import json\n",
    "from pydub import AudioSegment\n",
    "\n",
    "\n",
    "# ✅ FastAPI 서버 생성\n",
    "app = FastAPI()\n",
    "\n",
    "# ✅ MySQL 연결 설정\n",
    "DB_CONFIG = {\n",
    "    \"host\": \"project-db-cgi.smhrd.com\",\n",
    "    \"port\": 3307,\n",
    "    \"user\": \"TTEAM\",\n",
    "    \"password\": \"11111\",\n",
    "    \"database\": \"TTEAM\"\n",
    "}\n",
    "\n",
    "# 🔹 Hugging Face & OpenAI API 키 설정\n",
    "HUGGINGFACE_TOKEN = \"\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "\n",
    "# ✅ GPU 사용 여부 확인\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"🚀 실행 기기: {DEVICE}\")\n",
    "\n",
    "# ✅ Pydantic 데이터 모델\n",
    "class AudioProcessingRequest(BaseModel):\n",
    "    meeting_idx: int #36\n",
    "    user_idx: int #3\n",
    "    file_name: str #/content/drive/MyDrive/실전/record/aaa.wav  # 업로드된 파일 URL\n",
    "\n",
    "# ✅ OpenAI 클라이언트 생성\n",
    "client = openai.OpenAI()\n",
    "\n",
    "# ✅ Faiss DB 저장 경로\n",
    "FAISS_DIR = \"/content/drive/MyDrive/실전/faiss\"\n",
    "FAISS_INDEX_FILE = os.path.join(FAISS_DIR, \"faiss_test.index\")\n",
    "# os.makedirs(FAISS_DIR, exist_ok=True)\n",
    "\n",
    "# ✅ Faiss DB 로드 또는 초기화\n",
    "def load_or_init_faiss(embedding_dimension):\n",
    "    if os.path.exists(FAISS_INDEX_FILE):\n",
    "        return faiss.read_index(FAISS_INDEX_FILE)\n",
    "    else:\n",
    "        base_index = faiss.IndexFlatL2(embedding_dimension)\n",
    "        return faiss.IndexIDMap2(base_index)\n",
    "\n",
    "# ✅ Faiss에서 현재 저장된 마지막 `chunk_idx` 가져오기\n",
    "def get_next_chunk_idx_faiss(index):\n",
    "    if index.ntotal == 0:\n",
    "        return 1  # 첫 번째 청크라면 1부터 시작\n",
    "\n",
    "    stored_ids = faiss.vector_to_array(index.id_map)\n",
    "    last_chunk_idx = np.max(stored_ids)\n",
    "\n",
    "    return int(last_chunk_idx) + 1  # 마지막 `chunk_idx`에서 +1 증가\n",
    "\n",
    "# ✅ 청크 분할 및 MySQL 저장 함수\n",
    "def save_chunks_to_db(chunks, meeting_idx, user_idx, embeddings):\n",
    "    conn = pymysql.connect(**DB_CONFIG)\n",
    "    try:\n",
    "        with conn.cursor() as cursor:\n",
    "            sql_chunks = \"\"\"\n",
    "            INSERT INTO chunks (chunk_idx, meeting_idx, user_idx, chunk_text, created_at)\n",
    "            VALUES (%s, %s, %s, %s, NOW())\n",
    "            \"\"\"\n",
    "\n",
    "            index = load_or_init_faiss(embeddings.shape[1])\n",
    "            next_chunk_idx = get_next_chunk_idx_faiss(index)\n",
    "            print(next_chunk_idx)\n",
    "\n",
    "            ids = []\n",
    "            vectors = []\n",
    "\n",
    "            for i, chunk in enumerate(chunks):\n",
    "                current_idx = next_chunk_idx + i\n",
    "                cursor.execute(sql_chunks, (current_idx, meeting_idx, user_idx, chunk))\n",
    "\n",
    "                ids.append(current_idx)\n",
    "                vectors.append(embeddings[i])\n",
    "\n",
    "            index.add_with_ids(np.array(vectors), np.array(ids))\n",
    "            faiss.write_index(index, FAISS_INDEX_FILE)\n",
    "\n",
    "        conn.commit()\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "# 🔹 시간을 `MM:SS` 형식으로 변환\n",
    "def format_time(seconds):\n",
    "    minutes = int(seconds // 60)\n",
    "    seconds = int(seconds % 60)\n",
    "    return f\"{minutes:02}:{seconds:02}\"\n",
    "\n",
    "# 🔹 같은 참여자의 연속된 발언을 병합\n",
    "def merge_speaker_statements(speaker_texts):\n",
    "    merged_results = []\n",
    "    previous_speaker = None\n",
    "    previous_text = \"\"\n",
    "    previous_time = \"\"\n",
    "\n",
    "    for line in speaker_texts:\n",
    "        match = re.match(r\"(참여자_\\d+) (\\d{2}:\\d{2}) (.+)\", line)\n",
    "        if match:\n",
    "            speaker, time, text = match.groups()\n",
    "            if speaker == previous_speaker:\n",
    "                previous_text += \" \" + text\n",
    "            else:\n",
    "                if previous_speaker is not None:\n",
    "                    merged_results.append(f\"{previous_speaker} {previous_time} {previous_text}\")\n",
    "                previous_speaker, previous_text, previous_time = speaker, text, time\n",
    "\n",
    "    if previous_speaker is not None:\n",
    "        merged_results.append(f\"{previous_speaker} {previous_time} {previous_text}\")\n",
    "\n",
    "    return merged_results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 🔹 Faiss DB 로드\n",
    "def load_or_init_faiss(embedding_dimension):\n",
    "    if os.path.exists(FAISS_INDEX_FILE):\n",
    "        return faiss.read_index(FAISS_INDEX_FILE)\n",
    "    else:\n",
    "        base_index = faiss.IndexFlatL2(embedding_dimension)\n",
    "        return faiss.IndexIDMap2(base_index)\n",
    "\n",
    "\n",
    "# 🔹 Faiss DB 저장\n",
    "def save_faiss(index):\n",
    "    faiss.write_index(index, FAISS_INDEX_FILE)\n",
    "\n",
    "\n",
    "\n",
    "# # 🔹 Faiss 검색 테스트\n",
    "# query_text = \"WTO 의료시장 개방\"\n",
    "# query_embedding = kosimcse_model.encode([query_text])\n",
    "# distances, indices = index.search(np.array(query_embedding), 3)\n",
    "\n",
    "# print(\"\\n🔍 검색 결과:\")\n",
    "# for rank, (idx, distance) in enumerate(zip(indices[0], distances[0]), start=1):\n",
    "#     print(f\"  {rank}. ID: {idx}, 거리: {distance}\")\n",
    "\n",
    "# 🔹 요약 생성\n",
    "def generate_summary(text_with_speakers):\n",
    "    prompts = {\n",
    "        \"summary\": \"다음 회의록을 요약해줘.\",\n",
    "        \"subject\": \"다음 회의록에서 주요 주제를 한 문장으로 요약해줘.\",\n",
    "        \"positive\": \"다음 회의록을 기반으로 긍정적인 피드백을 작성해줘.참여자들에게도\",\n",
    "        \"negative\": \"다음 회의록을 기반으로 부정적인 피드백을 작성해줘.참여자들에게도\"\n",
    "    }\n",
    "\n",
    "    summary_json = {}  # 결과 저장용 딕셔너리\n",
    "\n",
    "    for key, prompt in prompts.items():\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",  # 최신 모델 사용\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"당신은 전문 회의 요약가입니다.\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"{prompt}\\n\\n{text_with_speakers}\"}\n",
    "                ],\n",
    "                max_tokens=500,  # 요약 길이 제한\n",
    "                temperature=0.3,  # 안정적인 답변을 위해 낮은 온도 설정\n",
    "            )\n",
    "            summary_json[key] = response.choices[0].message.content.strip()\n",
    "        except Exception as e:\n",
    "            summary_json[key] = f\"⚠️ 요약 생성 실패: {str(e)}\"\n",
    "\n",
    "    return summary_json\n",
    "\n",
    "# ✅ 음성 파일의 총 길이 추출\n",
    "def get_audio_length(file_path):\n",
    "    audio = AudioSegment.from_file(file_path)\n",
    "    return int(len(audio) / 1000)  # ms → 초 변환\n",
    "\n",
    "# ✅ Kiwi 기반 키워드 추출 함수 (전체 키워드 가져오기)\n",
    "def extract_keywords(text):\n",
    "    kiwi = Kiwi()\n",
    "    tokens = kiwi.tokenize(text)\n",
    "\n",
    "    # 🔹 명사(NNG, NNP)만 추출\n",
    "    nouns = [token.form for token in tokens if token.tag in ['NNG', 'NNP']]\n",
    "\n",
    "    # 🔹 등장 횟수 계산\n",
    "    word_counts = Counter(nouns)\n",
    "\n",
    "    # 🔹 JSON 형태로 반환 (키워드: 등장 횟수)\n",
    "    return dict(word_counts)\n",
    "\n",
    "\n",
    "# ✅ FastAPI 엔드포인트: 음성 처리 및 MySQL 저장\n",
    "@app.post(\"/process_audio/\")\n",
    "async def process_audio(request: AudioProcessingRequest):\n",
    "    file_path = os.path.join(\"/content/drive/MyDrive/실전/data/records\", request.file_name)\n",
    "\n",
    "    # ✅ 음성 파일 길이 가져오기\n",
    "    record_time = get_audio_length(file_path)\n",
    "\n",
    "\n",
    "    # 🔹 Pyannote 화자 분리 모델 로드\n",
    "    print(\"🔍 화자 분리 모델 다운로드 중...\")\n",
    "    pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization\", use_auth_token=HUGGINGFACE_TOKEN)\n",
    "\n",
    "    # ✅ 화자 분리 실행\n",
    "    diarization = pipeline(file_path)\n",
    "    pipeline.to(torch.device(\"cuda\"))\n",
    "\n",
    "\n",
    "    # ✅ STT 모델 선언\n",
    "\n",
    "    model = whisper.load_model(\"large-v3\", device=DEVICE)\n",
    "\n",
    "\n",
    "    # ✅ STT 변환 실행\n",
    "    speaker_map = {}\n",
    "    speaker_count = 1\n",
    "    speaker_texts = []\n",
    "\n",
    "    audio = AudioSegment.from_wav(file_path)\n",
    "    print(file_path)\n",
    "    for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "        start_ms = int(turn.start * 1000)  # 초를 밀리초로 변환\n",
    "        end_ms = int(turn.end * 1000)\n",
    "        start_time_formatted = format_time(turn.start)  # ⏳ 시간 변환 (MM:SS)\n",
    "        print(start_time_formatted)\n",
    "        # 오디오 구간 추출\n",
    "        segment = audio[start_ms:end_ms]\n",
    "        segment_file = f\"segment_{speaker}_{start_ms}.wav\"\n",
    "        segment.export(segment_file, format=\"wav\")\n",
    "\n",
    "        # Whisper로 STT 수행\n",
    "        result = model.transcribe(segment_file, language='ko')\n",
    "        text = result[\"text\"]\n",
    "        print(text)\n",
    "        speaker = str(speaker).replace('SPEAKER', '참여자')\n",
    "        speaker_texts.append(f'{speaker} {start_time_formatted} {text}')\n",
    "\n",
    "\n",
    "    # 🔹 같은 참여자의 발언 병합\n",
    "    merged_texts = merge_speaker_statements(speaker_texts)\n",
    "    print(merged_texts)\n",
    "\n",
    "    cleaned_text = \"\\n\".join(merged_texts)\n",
    "    print(f\"✅ STT 완료! 텍스트 길이: {len(cleaned_text)}\")\n",
    "\n",
    "    # 🔹 키워드 & 청크 분할용 화자 정보 제거\n",
    "    text_without_speakers = re.sub(r\"참여자_\\d+ \\d{2}:\\d{2} \", \"\", cleaned_text)\n",
    "\n",
    "    # 🔹 청크 분할\n",
    "    print(\"📝 텍스트 청크 분할 중...\")\n",
    "    text_splitter = SemanticChunker(OpenAIEmbeddings(), breakpoint_threshold_type=\"percentile\", breakpoint_threshold_amount=70)\n",
    "    chunks = text_splitter.split_text(text_without_speakers)\n",
    "    print(f\"✅ 청크 분할 완료! 총 {len(chunks)}개\")\n",
    "\n",
    "    # 🔹 KoSimCSE로 임베딩\n",
    "    print(\"📊 KoSimCSE Embedding 생성 중...\")\n",
    "    kosimcse_model = SentenceTransformer(\"BM-K/KoSimCSE-roberta-multitask\", device=DEVICE)\n",
    "    embeddings = kosimcse_model.encode(chunks, convert_to_tensor=True).cpu().numpy()\n",
    "    embedding_dimension = embeddings.shape[1]\n",
    "    print(f\"✅ 임베딩 완료! 벡터 크기: {embedding_dimension}\")\n",
    "\n",
    "    index = load_or_init_faiss(embedding_dimension)\n",
    "\n",
    "    # ✅ 키워드 추출\n",
    "    keywords = extract_keywords(text_without_speakers)\n",
    "\n",
    "    # ✅ 요약 생성\n",
    "    summary_json = generate_summary(cleaned_text)\n",
    "    print(f\"✅ 요약 완료! \\n{summary_json}\")\n",
    "\n",
    "    # ✅ MySQL 저장\n",
    "    conn = pymysql.connect(**DB_CONFIG)\n",
    "    try:\n",
    "        with conn.cursor() as cursor:\n",
    "            # 🔹 records 테이블에 데이터 저장\n",
    "\n",
    "            sql_records = \"\"\"\n",
    "            INSERT INTO records (meeting_idx, file_url, record_time, record_text, text_summary, uploaded_at, text_keyword)\n",
    "            VALUES (%s, %s, %s, %s, %s, now(), %s)\n",
    "            \"\"\"\n",
    "            print(request.meeting_idx)\n",
    "\n",
    "            cursor.execute(sql_records, (\n",
    "                request.meeting_idx, request.file_name, record_time, cleaned_text,\n",
    "                json.dumps(summary_json, ensure_ascii=False),\n",
    "                json.dumps(keywords, ensure_ascii=False)\n",
    "            ))\n",
    "            print(request.meeting_idx)\n",
    "\n",
    "\n",
    "        conn.commit()\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "    # ✅ Faiss 및 MySQL에 저장\n",
    "    save_chunks_to_db(chunks, request.meeting_idx, request.user_idx, embeddings)\n",
    "\n",
    "    return {\n",
    "        \"status\": \"success\",\n",
    "        \"meeting_idx\": request.meeting_idx,\n",
    "        \"record_time\": record_time,\n",
    "        \"record_text\": cleaned_text,\n",
    "        \"text_summary\": summary_json,\n",
    "        \"text_keyword\": keywords,\n",
    "        \"chunks_count\": len(chunks)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2539,
     "status": "ok",
     "timestamp": 1742952262242,
     "user": {
      "displayName": "기모띠",
      "userId": "12217281576736575114"
     },
     "user_tz": -540
    },
    "id": "UjACKHgjw_UT",
    "outputId": "5d2c9d1c-dd93-4cfd-d0a4-7b45e7e70153"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyngrok\n",
      "  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
      "Downloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: pyngrok\n",
      "Successfully installed pyngrok-7.2.3\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 설치\n",
    "!pip install pyngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HK26ws_xxIgk",
    "outputId": "31d055ee-80cc-4fb3-fc4e-3e8d4b4f2147"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [52208]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:8001 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "공용 URL: https://104f-34-143-154-113.ngrok-free.app\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "from pyngrok import ngrok\n",
    "import uvicorn\n",
    "ngrok.set_auth_token(\"2ubn5t4R3wCYRMwoqiNdutdH09j_4qNznUTidUZPKuvCBpBAx\")\n",
    "ngrok_tunnel = ngrok.connect(8001)\n",
    "print('공용 URL:', ngrok_tunnel.public_url)\n",
    "nest_asyncio.apply()\n",
    "uvicorn.run(app, port=8001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XO6pIDttBMay"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
