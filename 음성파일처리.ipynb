{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30418,
     "status": "ok",
     "timestamp": 1742952190617,
     "user": {
      "displayName": "ê¸°ëª¨ë ",
      "userId": "12217281576736575114"
     },
     "user_tz": -540
    },
    "id": "ly5V36KDs-gi",
    "outputId": "156a81bb-8188-4ef8-9497-1db06750f98f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m34.7/34.7 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m898.7/898.7 kB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m818.9/818.9 kB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m125.9/125.9 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m824.8/824.8 kB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m960.9/960.9 kB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m823.0/823.0 kB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m231.8/231.8 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for kiwipiepy_model (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install -q \\\n",
    "    pyannote.audio \\\n",
    "    faiss-cpu \\\n",
    "    sentence-transformers \\\n",
    "    openai \\\n",
    "    langchain_experimental \\\n",
    "    kiwipiepy \\\n",
    "    torchaudio \\\n",
    "    torch \\\n",
    "    numpy \\\n",
    "    pandas \\\n",
    "    tqdm \\\n",
    "    huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25885,
     "status": "ok",
     "timestamp": 1742951660486,
     "user": {
      "displayName": "ê¸°ëª¨ë ",
      "userId": "12217281576736575114"
     },
     "user_tz": -540
    },
    "id": "Qgh6VSLQAif8",
    "outputId": "142622b8-4087-4c28-88a0-a4603b0a088e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2314,
     "status": "ok",
     "timestamp": 1742952199831,
     "user": {
      "displayName": "ê¸°ëª¨ë ",
      "userId": "12217281576736575114"
     },
     "user_tz": -540
    },
    "id": "FDnItIdatSzs",
    "outputId": "ae2dd6b9-9975-45a6-92ca-ad2d96162bd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (0.25.1)\n"
     ]
    }
   ],
   "source": [
    "pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2309,
     "status": "ok",
     "timestamp": 1742952202141,
     "user": {
      "displayName": "ê¸°ëª¨ë ",
      "userId": "12217281576736575114"
     },
     "user_tz": -540
    },
    "id": "yfuIaotytXsl",
    "outputId": "ec3bf3b8-35cb-4f26-8ade-d6f5f59e2c56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymysql in /usr/local/lib/python3.11/dist-packages (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2812,
     "status": "ok",
     "timestamp": 1742952204955,
     "user": {
      "displayName": "ê¸°ëª¨ë ",
      "userId": "12217281576736575114"
     },
     "user_tz": -540
    },
    "id": "yAAdrFbotZE7",
    "outputId": "6dbe52eb-d390-4163-ed44-ebbeaa46e112"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.21)\n",
      "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.11/dist-packages (0.3.10)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.48)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.7)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.18)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.39)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.68.2)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.9.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.9.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain) (3.0.0)\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2413,
     "status": "ok",
     "timestamp": 1742952207369,
     "user": {
      "displayName": "ê¸°ëª¨ë ",
      "userId": "12217281576736575114"
     },
     "user_tz": -540
    },
    "id": "r_WZOMnEtagb",
    "outputId": "b037a65d-04e9-4796-855a-2475da6f76d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (0.115.12)\n",
      "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (0.34.0)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (0.46.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi) (2.10.6)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.12.2)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.1.8)\n",
      "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.27.2)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install fastapi uvicorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8723,
     "status": "ok",
     "timestamp": 1742952216093,
     "user": {
      "displayName": "ê¸°ëª¨ë ",
      "userId": "12217281576736575114"
     },
     "user_tz": -540
    },
    "id": "-O_9mPMAt3pT",
    "outputId": "7169b83b-97e0-4deb-effc-771f834cfee9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-oyy9tz3l\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-oyy9tz3l\n",
      "  Resolved https://github.com/openai/whisper.git to commit 517a43ecd132a2089d85f4ebc044728a71d49f6e\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (10.6.0)\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (0.60.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (2.0.2)\n",
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (0.9.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (2.6.0+cu124)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (4.67.1)\n",
      "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (3.2.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper==20240930) (0.43.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20240930) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper==20240930) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper==20240930) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/openai/whisper.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12928,
     "status": "ok",
     "timestamp": 1742963672304,
     "user": {
      "displayName": "ê¸°ëª¨ë ",
      "userId": "12217281576736575114"
     },
     "user_tz": -540
    },
    "id": "J5vxTAVXs_Zb",
    "outputId": "246b72e3-9df4-4630-a55b-f31beacb71d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ì‹¤í–‰ ê¸°ê¸°: cuda\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import torch\n",
    "import faiss\n",
    "import numpy as np\n",
    "import openai\n",
    "from pyannote.audio import Pipeline\n",
    "import whisper\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from collections import Counter\n",
    "from kiwipiepy import Kiwi\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "from pydub import AudioSegment\n",
    "# send pipeline to GPU (when available)\n",
    "import torch\n",
    "import pymysql\n",
    "import json\n",
    "from pydub import AudioSegment\n",
    "\n",
    "\n",
    "# âœ… FastAPI ì„œë²„ ìƒì„±\n",
    "app = FastAPI()\n",
    "\n",
    "# âœ… MySQL ì—°ê²° ì„¤ì •\n",
    "DB_CONFIG = {\n",
    "    \"host\": \"project-db-cgi.smhrd.com\",\n",
    "    \"port\": 3307,\n",
    "    \"user\": \"TTEAM\",\n",
    "    \"password\": \"11111\",\n",
    "    \"database\": \"TTEAM\"\n",
    "}\n",
    "\n",
    "# ğŸ”¹ Hugging Face & OpenAI API í‚¤ ì„¤ì •\n",
    "HUGGINGFACE_TOKEN = \"\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "\n",
    "# âœ… GPU ì‚¬ìš© ì—¬ë¶€ í™•ì¸\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"ğŸš€ ì‹¤í–‰ ê¸°ê¸°: {DEVICE}\")\n",
    "\n",
    "# âœ… Pydantic ë°ì´í„° ëª¨ë¸\n",
    "class AudioProcessingRequest(BaseModel):\n",
    "    meeting_idx: int #36\n",
    "    user_idx: int #3\n",
    "    file_name: str #/content/drive/MyDrive/á„‰á…µá†¯á„Œá…¥á†«/record/aaa.wav  # ì—…ë¡œë“œëœ íŒŒì¼ URL\n",
    "\n",
    "# âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±\n",
    "client = openai.OpenAI()\n",
    "\n",
    "# âœ… Faiss DB ì €ì¥ ê²½ë¡œ\n",
    "FAISS_DIR = \"/content/drive/MyDrive/ì‹¤ì „/faiss\"\n",
    "FAISS_INDEX_FILE = os.path.join(FAISS_DIR, \"faiss_test.index\")\n",
    "# os.makedirs(FAISS_DIR, exist_ok=True)\n",
    "\n",
    "# âœ… Faiss DB ë¡œë“œ ë˜ëŠ” ì´ˆê¸°í™”\n",
    "def load_or_init_faiss(embedding_dimension):\n",
    "    if os.path.exists(FAISS_INDEX_FILE):\n",
    "        return faiss.read_index(FAISS_INDEX_FILE)\n",
    "    else:\n",
    "        base_index = faiss.IndexFlatL2(embedding_dimension)\n",
    "        return faiss.IndexIDMap2(base_index)\n",
    "\n",
    "# âœ… Faissì—ì„œ í˜„ì¬ ì €ì¥ëœ ë§ˆì§€ë§‰ `chunk_idx` ê°€ì ¸ì˜¤ê¸°\n",
    "def get_next_chunk_idx_faiss(index):\n",
    "    if index.ntotal == 0:\n",
    "        return 1  # ì²« ë²ˆì§¸ ì²­í¬ë¼ë©´ 1ë¶€í„° ì‹œì‘\n",
    "\n",
    "    stored_ids = faiss.vector_to_array(index.id_map)\n",
    "    last_chunk_idx = np.max(stored_ids)\n",
    "\n",
    "    return int(last_chunk_idx) + 1  # ë§ˆì§€ë§‰ `chunk_idx`ì—ì„œ +1 ì¦ê°€\n",
    "\n",
    "# âœ… ì²­í¬ ë¶„í•  ë° MySQL ì €ì¥ í•¨ìˆ˜\n",
    "def save_chunks_to_db(chunks, meeting_idx, user_idx, embeddings):\n",
    "    conn = pymysql.connect(**DB_CONFIG)\n",
    "    try:\n",
    "        with conn.cursor() as cursor:\n",
    "            sql_chunks = \"\"\"\n",
    "            INSERT INTO chunks (chunk_idx, meeting_idx, user_idx, chunk_text, created_at)\n",
    "            VALUES (%s, %s, %s, %s, NOW())\n",
    "            \"\"\"\n",
    "\n",
    "            index = load_or_init_faiss(embeddings.shape[1])\n",
    "            next_chunk_idx = get_next_chunk_idx_faiss(index)\n",
    "            print(next_chunk_idx)\n",
    "\n",
    "            ids = []\n",
    "            vectors = []\n",
    "\n",
    "            for i, chunk in enumerate(chunks):\n",
    "                current_idx = next_chunk_idx + i\n",
    "                cursor.execute(sql_chunks, (current_idx, meeting_idx, user_idx, chunk))\n",
    "\n",
    "                ids.append(current_idx)\n",
    "                vectors.append(embeddings[i])\n",
    "\n",
    "            index.add_with_ids(np.array(vectors), np.array(ids))\n",
    "            faiss.write_index(index, FAISS_INDEX_FILE)\n",
    "\n",
    "        conn.commit()\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "# ğŸ”¹ ì‹œê°„ì„ `MM:SS` í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "def format_time(seconds):\n",
    "    minutes = int(seconds // 60)\n",
    "    seconds = int(seconds % 60)\n",
    "    return f\"{minutes:02}:{seconds:02}\"\n",
    "\n",
    "# ğŸ”¹ ê°™ì€ ì°¸ì—¬ìì˜ ì—°ì†ëœ ë°œì–¸ì„ ë³‘í•©\n",
    "def merge_speaker_statements(speaker_texts):\n",
    "    merged_results = []\n",
    "    previous_speaker = None\n",
    "    previous_text = \"\"\n",
    "    previous_time = \"\"\n",
    "\n",
    "    for line in speaker_texts:\n",
    "        match = re.match(r\"(ì°¸ì—¬ì_\\d+) (\\d{2}:\\d{2}) (.+)\", line)\n",
    "        if match:\n",
    "            speaker, time, text = match.groups()\n",
    "            if speaker == previous_speaker:\n",
    "                previous_text += \" \" + text\n",
    "            else:\n",
    "                if previous_speaker is not None:\n",
    "                    merged_results.append(f\"{previous_speaker} {previous_time} {previous_text}\")\n",
    "                previous_speaker, previous_text, previous_time = speaker, text, time\n",
    "\n",
    "    if previous_speaker is not None:\n",
    "        merged_results.append(f\"{previous_speaker} {previous_time} {previous_text}\")\n",
    "\n",
    "    return merged_results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ğŸ”¹ Faiss DB ë¡œë“œ\n",
    "def load_or_init_faiss(embedding_dimension):\n",
    "    if os.path.exists(FAISS_INDEX_FILE):\n",
    "        return faiss.read_index(FAISS_INDEX_FILE)\n",
    "    else:\n",
    "        base_index = faiss.IndexFlatL2(embedding_dimension)\n",
    "        return faiss.IndexIDMap2(base_index)\n",
    "\n",
    "\n",
    "# ğŸ”¹ Faiss DB ì €ì¥\n",
    "def save_faiss(index):\n",
    "    faiss.write_index(index, FAISS_INDEX_FILE)\n",
    "\n",
    "\n",
    "\n",
    "# # ğŸ”¹ Faiss ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
    "# query_text = \"WTO ì˜ë£Œì‹œì¥ ê°œë°©\"\n",
    "# query_embedding = kosimcse_model.encode([query_text])\n",
    "# distances, indices = index.search(np.array(query_embedding), 3)\n",
    "\n",
    "# print(\"\\nğŸ” ê²€ìƒ‰ ê²°ê³¼:\")\n",
    "# for rank, (idx, distance) in enumerate(zip(indices[0], distances[0]), start=1):\n",
    "#     print(f\"  {rank}. ID: {idx}, ê±°ë¦¬: {distance}\")\n",
    "\n",
    "# ğŸ”¹ ìš”ì•½ ìƒì„±\n",
    "def generate_summary(text_with_speakers):\n",
    "    prompts = {\n",
    "        \"summary\": \"ë‹¤ìŒ íšŒì˜ë¡ì„ ìš”ì•½í•´ì¤˜.\",\n",
    "        \"subject\": \"ë‹¤ìŒ íšŒì˜ë¡ì—ì„œ ì£¼ìš” ì£¼ì œë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì¤˜.\",\n",
    "        \"positive\": \"ë‹¤ìŒ íšŒì˜ë¡ì„ ê¸°ë°˜ìœ¼ë¡œ ê¸ì •ì ì¸ í”¼ë“œë°±ì„ ì‘ì„±í•´ì¤˜.ì°¸ì—¬ìë“¤ì—ê²Œë„\",\n",
    "        \"negative\": \"ë‹¤ìŒ íšŒì˜ë¡ì„ ê¸°ë°˜ìœ¼ë¡œ ë¶€ì •ì ì¸ í”¼ë“œë°±ì„ ì‘ì„±í•´ì¤˜.ì°¸ì—¬ìë“¤ì—ê²Œë„\"\n",
    "    }\n",
    "\n",
    "    summary_json = {}  # ê²°ê³¼ ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬\n",
    "\n",
    "    for key, prompt in prompts.items():\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",  # ìµœì‹  ëª¨ë¸ ì‚¬ìš©\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"ë‹¹ì‹ ì€ ì „ë¬¸ íšŒì˜ ìš”ì•½ê°€ì…ë‹ˆë‹¤.\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"{prompt}\\n\\n{text_with_speakers}\"}\n",
    "                ],\n",
    "                max_tokens=500,  # ìš”ì•½ ê¸¸ì´ ì œí•œ\n",
    "                temperature=0.3,  # ì•ˆì •ì ì¸ ë‹µë³€ì„ ìœ„í•´ ë‚®ì€ ì˜¨ë„ ì„¤ì •\n",
    "            )\n",
    "            summary_json[key] = response.choices[0].message.content.strip()\n",
    "        except Exception as e:\n",
    "            summary_json[key] = f\"âš ï¸ ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {str(e)}\"\n",
    "\n",
    "    return summary_json\n",
    "\n",
    "# âœ… ìŒì„± íŒŒì¼ì˜ ì´ ê¸¸ì´ ì¶”ì¶œ\n",
    "def get_audio_length(file_path):\n",
    "    audio = AudioSegment.from_file(file_path)\n",
    "    return int(len(audio) / 1000)  # ms â†’ ì´ˆ ë³€í™˜\n",
    "\n",
    "# âœ… Kiwi ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ í•¨ìˆ˜ (ì „ì²´ í‚¤ì›Œë“œ ê°€ì ¸ì˜¤ê¸°)\n",
    "def extract_keywords(text):\n",
    "    kiwi = Kiwi()\n",
    "    tokens = kiwi.tokenize(text)\n",
    "\n",
    "    # ğŸ”¹ ëª…ì‚¬(NNG, NNP)ë§Œ ì¶”ì¶œ\n",
    "    nouns = [token.form for token in tokens if token.tag in ['NNG', 'NNP']]\n",
    "\n",
    "    # ğŸ”¹ ë“±ì¥ íšŸìˆ˜ ê³„ì‚°\n",
    "    word_counts = Counter(nouns)\n",
    "\n",
    "    # ğŸ”¹ JSON í˜•íƒœë¡œ ë°˜í™˜ (í‚¤ì›Œë“œ: ë“±ì¥ íšŸìˆ˜)\n",
    "    return dict(word_counts)\n",
    "\n",
    "\n",
    "# âœ… FastAPI ì—”ë“œí¬ì¸íŠ¸: ìŒì„± ì²˜ë¦¬ ë° MySQL ì €ì¥\n",
    "@app.post(\"/process_audio/\")\n",
    "async def process_audio(request: AudioProcessingRequest):\n",
    "    file_path = os.path.join(\"/content/drive/MyDrive/ì‹¤ì „/data/records\", request.file_name)\n",
    "\n",
    "    # âœ… ìŒì„± íŒŒì¼ ê¸¸ì´ ê°€ì ¸ì˜¤ê¸°\n",
    "    record_time = get_audio_length(file_path)\n",
    "\n",
    "\n",
    "    # ğŸ”¹ Pyannote í™”ì ë¶„ë¦¬ ëª¨ë¸ ë¡œë“œ\n",
    "    print(\"ğŸ” í™”ì ë¶„ë¦¬ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘...\")\n",
    "    pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization\", use_auth_token=HUGGINGFACE_TOKEN)\n",
    "\n",
    "    # âœ… í™”ì ë¶„ë¦¬ ì‹¤í–‰\n",
    "    diarization = pipeline(file_path)\n",
    "    pipeline.to(torch.device(\"cuda\"))\n",
    "\n",
    "\n",
    "    # âœ… STT ëª¨ë¸ ì„ ì–¸\n",
    "\n",
    "    model = whisper.load_model(\"large-v3\", device=DEVICE)\n",
    "\n",
    "\n",
    "    # âœ… STT ë³€í™˜ ì‹¤í–‰\n",
    "    speaker_map = {}\n",
    "    speaker_count = 1\n",
    "    speaker_texts = []\n",
    "\n",
    "    audio = AudioSegment.from_wav(file_path)\n",
    "    print(file_path)\n",
    "    for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "        start_ms = int(turn.start * 1000)  # ì´ˆë¥¼ ë°€ë¦¬ì´ˆë¡œ ë³€í™˜\n",
    "        end_ms = int(turn.end * 1000)\n",
    "        start_time_formatted = format_time(turn.start)  # â³ ì‹œê°„ ë³€í™˜ (MM:SS)\n",
    "        print(start_time_formatted)\n",
    "        # ì˜¤ë””ì˜¤ êµ¬ê°„ ì¶”ì¶œ\n",
    "        segment = audio[start_ms:end_ms]\n",
    "        segment_file = f\"segment_{speaker}_{start_ms}.wav\"\n",
    "        segment.export(segment_file, format=\"wav\")\n",
    "\n",
    "        # Whisperë¡œ STT ìˆ˜í–‰\n",
    "        result = model.transcribe(segment_file, language='ko')\n",
    "        text = result[\"text\"]\n",
    "        print(text)\n",
    "        speaker = str(speaker).replace('SPEAKER', 'ì°¸ì—¬ì')\n",
    "        speaker_texts.append(f'{speaker} {start_time_formatted} {text}')\n",
    "\n",
    "\n",
    "    # ğŸ”¹ ê°™ì€ ì°¸ì—¬ìì˜ ë°œì–¸ ë³‘í•©\n",
    "    merged_texts = merge_speaker_statements(speaker_texts)\n",
    "    print(merged_texts)\n",
    "\n",
    "    cleaned_text = \"\\n\".join(merged_texts)\n",
    "    print(f\"âœ… STT ì™„ë£Œ! í…ìŠ¤íŠ¸ ê¸¸ì´: {len(cleaned_text)}\")\n",
    "\n",
    "    # ğŸ”¹ í‚¤ì›Œë“œ & ì²­í¬ ë¶„í• ìš© í™”ì ì •ë³´ ì œê±°\n",
    "    text_without_speakers = re.sub(r\"ì°¸ì—¬ì_\\d+ \\d{2}:\\d{2} \", \"\", cleaned_text)\n",
    "\n",
    "    # ğŸ”¹ ì²­í¬ ë¶„í• \n",
    "    print(\"ğŸ“ í…ìŠ¤íŠ¸ ì²­í¬ ë¶„í•  ì¤‘...\")\n",
    "    text_splitter = SemanticChunker(OpenAIEmbeddings(), breakpoint_threshold_type=\"percentile\", breakpoint_threshold_amount=70)\n",
    "    chunks = text_splitter.split_text(text_without_speakers)\n",
    "    print(f\"âœ… ì²­í¬ ë¶„í•  ì™„ë£Œ! ì´ {len(chunks)}ê°œ\")\n",
    "\n",
    "    # ğŸ”¹ KoSimCSEë¡œ ì„ë² ë”©\n",
    "    print(\"ğŸ“Š KoSimCSE Embedding ìƒì„± ì¤‘...\")\n",
    "    kosimcse_model = SentenceTransformer(\"BM-K/KoSimCSE-roberta-multitask\", device=DEVICE)\n",
    "    embeddings = kosimcse_model.encode(chunks, convert_to_tensor=True).cpu().numpy()\n",
    "    embedding_dimension = embeddings.shape[1]\n",
    "    print(f\"âœ… ì„ë² ë”© ì™„ë£Œ! ë²¡í„° í¬ê¸°: {embedding_dimension}\")\n",
    "\n",
    "    index = load_or_init_faiss(embedding_dimension)\n",
    "\n",
    "    # âœ… í‚¤ì›Œë“œ ì¶”ì¶œ\n",
    "    keywords = extract_keywords(text_without_speakers)\n",
    "\n",
    "    # âœ… ìš”ì•½ ìƒì„±\n",
    "    summary_json = generate_summary(cleaned_text)\n",
    "    print(f\"âœ… ìš”ì•½ ì™„ë£Œ! \\n{summary_json}\")\n",
    "\n",
    "    # âœ… MySQL ì €ì¥\n",
    "    conn = pymysql.connect(**DB_CONFIG)\n",
    "    try:\n",
    "        with conn.cursor() as cursor:\n",
    "            # ğŸ”¹ records í…Œì´ë¸”ì— ë°ì´í„° ì €ì¥\n",
    "\n",
    "            sql_records = \"\"\"\n",
    "            INSERT INTO records (meeting_idx, file_url, record_time, record_text, text_summary, uploaded_at, text_keyword)\n",
    "            VALUES (%s, %s, %s, %s, %s, now(), %s)\n",
    "            \"\"\"\n",
    "            print(request.meeting_idx)\n",
    "\n",
    "            cursor.execute(sql_records, (\n",
    "                request.meeting_idx, request.file_name, record_time, cleaned_text,\n",
    "                json.dumps(summary_json, ensure_ascii=False),\n",
    "                json.dumps(keywords, ensure_ascii=False)\n",
    "            ))\n",
    "            print(request.meeting_idx)\n",
    "\n",
    "\n",
    "        conn.commit()\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "    # âœ… Faiss ë° MySQLì— ì €ì¥\n",
    "    save_chunks_to_db(chunks, request.meeting_idx, request.user_idx, embeddings)\n",
    "\n",
    "    return {\n",
    "        \"status\": \"success\",\n",
    "        \"meeting_idx\": request.meeting_idx,\n",
    "        \"record_time\": record_time,\n",
    "        \"record_text\": cleaned_text,\n",
    "        \"text_summary\": summary_json,\n",
    "        \"text_keyword\": keywords,\n",
    "        \"chunks_count\": len(chunks)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2539,
     "status": "ok",
     "timestamp": 1742952262242,
     "user": {
      "displayName": "ê¸°ëª¨ë ",
      "userId": "12217281576736575114"
     },
     "user_tz": -540
    },
    "id": "UjACKHgjw_UT",
    "outputId": "5d2c9d1c-dd93-4cfd-d0a4-7b45e7e70153"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyngrok\n",
      "  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
      "Downloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: pyngrok\n",
      "Successfully installed pyngrok-7.2.3\n"
     ]
    }
   ],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "!pip install pyngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HK26ws_xxIgk",
    "outputId": "31d055ee-80cc-4fb3-fc4e-3e8d4b4f2147"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [52208]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:8001 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê³µìš© URL: https://104f-34-143-154-113.ngrok-free.app\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "from pyngrok import ngrok\n",
    "import uvicorn\n",
    "ngrok.set_auth_token(\"2ubn5t4R3wCYRMwoqiNdutdH09j_4qNznUTidUZPKuvCBpBAx\")\n",
    "ngrok_tunnel = ngrok.connect(8001)\n",
    "print('ê³µìš© URL:', ngrok_tunnel.public_url)\n",
    "nest_asyncio.apply()\n",
    "uvicorn.run(app, port=8001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XO6pIDttBMay"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
